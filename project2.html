<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Project 2 — Fun with Filters & Frequencies</title>
  <meta name="theme-color" content="#0f1226"/>
  <link rel="stylesheet" href="assets/style.css?v=2"/>
</head>
<body>
  <!-- Top breadcrumb -->
  <nav class="topbar">
    <div class="container" style="padding:10px 24px">
      <div class="breadcrumb">
        <a href="index.html">← Back to Home</a>
        <span>·</span>
        <span>Project 2 — Fun with Filters & Frequencies</span>
      </div>
    </div>
  </nav>

  <main class="container">
    <!-- Intro -->
    <section class="section" id="overview">
      <h1 class="proj-title">Project 2 — Fun with Filters & Frequencies</h1>
    </section>

    <!-- Part 1 header -->
    <section class="section" id="part1">
      <h2>Part 1 — Filters and Edges</h2>
      <p>I implemented two spatial-domain 2D convolutions in NumPy and compared them against <span class="kbd">scipy.signal.convolve2d</span>. Then I computed partial derivatives, gradient magnitudes, and binarized edge maps; finally I constructed Gaussian kernels via <span class="kbd">cv2.getGaussianKernel</span>, formed DoG (Derivative-of-Gaussian) filters, and compared their results to finite differences.</p>
    </section>

    <!-- Part 1.1 -->
    <section class="section" id="part1-1">
      <h2>Part 1.1 — Convolution (NumPy-only) & Comparison with SciPy</h2>
      <p><strong>Implementations.</strong> I wrote two versions:</p>
      <ul>
        <li><span class="kbd">conv2d_4loop</span>: explicit loops over image <em>and</em> kernel indices.</li>
        <li><span class="kbd">conv2d_2loop</span>: loops over pixels only; the inner multiply+sum is vectorized.</li>
      </ul>

      <!-- Key code snippets (concise “idea” only) -->
<div class="gallery grid-code">
  <figure class="figure">
    <pre class="codeblock"><code># (Idea) Flip kernel → zero-pad → 4 nested loops
def conv2d_4loop(img, K, padding):
    k = np.flipud(np.fliplr(K))
    ph, pw = padding if isinstance(padding, tuple) else (padding, padding)
    x = np.pad(img, ((ph, ph), (pw, pw)), mode='constant', constant_values=0)
    H, W = img.shape; kh, kw = k.shape
    out = np.zeros((H, W))
    for i in range(H):
        for j in range(W):
            s = 0.0
            for u in range(kh):
                for v in range(kw):
                    s += x[i+u, j+v] * k[u, v]
            out[i, j] = s
    return out</code></pre>
    <figcaption class="figcap">Naive 4-loop: clearest but slowest (Python loops over pixels and kernel).</figcaption>
  </figure>

  <figure class="figure">
    <pre class="codeblock"><code># (Idea) Same setup → loop over pixels only → vectorized inner product
def conv2d_2loop(img, K, padding):
    k = np.flipud(np.fliplr(K))
    ph, pw = padding if isinstance(padding, tuple) else (padding, padding)
    x = np.pad(img, ((ph, ph), (pw, pw)), mode='constant', constant_values=0)
    H, W = img.shape; kh, kw = k.shape
    out = np.zeros((H, W))
    for i in range(H):
        for j in range(W):
            patch = x[i:i+kh, j:j+kw]
            out[i, j] = np.sum(patch * k)   
    return out</code></pre>
    <figcaption class="figcap">2-loop: much faster in practice; inner work is NumPy-vectorized.</figcaption>
  </figure>
</div>

      <div class="figure" style="margin-top:14px">
<pre><code># (Idea) Quick correctness check vs SciPy (same padding)
ref = convolve2d(img, K, mode='same', boundary='fill', fillvalue=0)
err = np.max(np.abs(conv2d_2loop(img, K, padding=(K.shape[0]//2, K.shape[1]//2)) - ref))
print(f"max|custom - scipy| = {err:.2e}")</code></pre>
        <div class="figcap">Use SciPy as a reference with identical boundary conditions.</div>
      </div>

      <div class="answer" style="margin-top:12px">
        <div class="label">Answer — Runtime & Boundary Handling</div>
        <p><strong>Runtime.</strong> All are <span class="kbd">O(H·W·kh·kw)</span>. In practice: <em>4-loop</em> (slowest) ≪ <em>2-loop</em> ≪ SciPy’s <span class="kbd">convolve2d</span> (fastest, optimized C/FFT). </p>
        <p><strong>Boundaries.</strong> I pad with zeros to keep output size the same (<span class="kbd">np.pad(..., mode='constant', constant_values=0)</span>). For fair comparison I call SciPy with <span class="kbd">mode='same', boundary='fill', fillvalue=0</span>. (Alternatives like <span class="kbd">reflect</span> can reduce edge artifacts.)</p>
      </div>
    </section>

    <!-- Part 1.2 -->
    <section class="section" id="part1-2">
      <h2>Part 1.2 — Partial Derivatives, Gradient Magnitude, and Binarized Edges</h2>
      <p>I use the finite-difference kernels <span class="kbd">Dx = [[1, 0, -1]]</span> and <span class="kbd">Dy = Dxᵀ</span>. I apply zero padding of width 1 along the axis of the derivative so output dimensions match the input. Gradient magnitude is <span class="kbd">√(gx² + gy²)</span>, normalized to [0,1].</p>

      <div class="gallery">
        <figure class="figure">
          <img src="p2/p12_gx_fd.png" alt="Partial derivative in x"/>
          <figcaption class="figcap">Partial derivative <span class="kbd">Iₓ</span>.</figcaption>
        </figure>
        <figure class="figure">
          <img src="p2/p12_gy_fd.png" alt="Partial derivative in y"/>
          <figcaption class="figcap">Partial derivative <span class="kbd">Iᵧ</span>.</figcaption>
        </figure>
        <figure class="figure">
          <img src="p2/p12_gradmag_fd.png" alt="Gradient magnitude"/>
          <figcaption class="figcap">Gradient magnitude <span class="kbd">‖∇I‖</span> after normalization.</figcaption>
        </figure>
        <figure class="figure">
          <img src="p2/p12_edges_fd.png" alt="Binarized edge map"/>
          <figcaption class="figcap">Binarized edges using a percentile-based global threshold.</figcaption>
        </figure>
      </div>

      <div class="answer">
        <div class="label">Noise vs. edge completeness — threshold choice</div>
        <p>I set the threshold automatically from the gradient-magnitude distribution using <span class="kbd">percentile=90</span>. This retains salient boundaries while suppressing weaker texture/noise. Larger percentiles simplify edges; smaller percentiles recover faint edges but admit noise.</p>
      </div>
    </section>

    <!-- Part 1.3 -->
    <section class="section" id="part1-3">
      <h2>Part 1.3 — Gaussian Smoothing & DoG (Derivative-of-Gaussian)</h2>
      <p>I construct Gaussian kernels with <span class="kbd">cv2.getGaussianKernel</span> conceptually; in code I generate a 2D Gaussian via a separable 1D vector (<span class="kbd">gaussian_kernel2d</span>). Two equivalent routes to gradients:</p>
      <ol>
        <li><em>Smooth then differentiate:</em> blur with <span class="kbd">G(σ)</span>, then convolve with <span class="kbd">Dx</span>/<span class="kbd">Dy</span>.</li>
        <li><em>Single pass DoG:</em> pre-convolve <span class="kbd">G</span> with <span class="kbd">Dx/Dy</span> to form DoG kernels; convolve image once per axis. I verify they match (up to boundary/float eps).</li>
      </ol>

      <div class="gallery">
        <figure class="figure">
          <img src="p2/p13_gx_smooth.png" alt="Smoothed x-derivative"/>
          <figcaption class="figcap">Smoothed x-derivative (route 1).</figcaption>
        </figure>
        <figure class="figure">
          <img src="p2/p13_gy_smooth.png" alt="Smoothed y-derivative"/>
          <figcaption class="figcap">Smoothed y-derivative (route 1).</figcaption>
        </figure>
        <figure class="figure">
          <img src="p2/p13_gradmag_smooth.png" alt="Grad magnitude after smoothing"/>
          <figcaption class="figcap">Gradient magnitude after smoothing.</figcaption>
        </figure>
        <figure class="figure">
          <img src="p2/p13_edges_smooth.png" alt="Edges after smoothing"/>
          <figcaption class="figcap">Binarized edges (same percentile for parity).</figcaption>
        </figure>
      </div>

      <div class="gallery">
        <figure class="figure">
          <img src="p2/p13_gx_dog.png" alt="DoG x-derivative"/>
          <figcaption class="figcap">DoG x-derivative (route 2).</figcaption>
        </figure>
        <figure class="figure">
          <img src="p2/p13_gy_dog.png" alt="DoG y-derivative"/>
          <figcaption class="figcap">DoG y-derivative (route 2).</figcaption>
        </figure>
        <figure class="figure">
          <img src="p2/p13_gradmag_dog.png" alt="DoG grad magnitude"/>
          <figcaption class="figcap">DoG gradient magnitude (normalized).</figcaption>
        </figure>
        <figure class="figure">
          <img src="p2/p13_edges_dog.png" alt="DoG edges"/>
          <figcaption class="figcap">Binarized edges from DoG magnitude.</figcaption>
        </figure>
      </div>
    </section>

    <!-- ====================== PART 2 ====================== -->
    <section class="section" id="part2">
      <h2>Part 2 — Applications</h2>
      <p>Unsharp masking for sharpening, hybrid images, Gaussian/Laplacian <em>stacks</em>, and multi-resolution blending.</p>
    </section>

    <!-- 2.1 -->
    <section class="section" id="part2-1">
      <h2>Part 2.1 — Image “Sharpening” (Unsharp Mask)</h2>
      <p><strong>Idea.</strong> Decompose image as <span class="kbd">I = low + high</span> using a Gaussian low-pass <span class="kbd">G(σ)</span>. Boost high frequencies: <span class="kbd">I' = I + α·high = (1+α)·I − α·(I*G)</span>. As a single convolution: <span class="kbd">K<sub>unsharp</sub> = (1+α)·δ − α·G</span>, then <span class="kbd">I' = I * K<sub>unsharp</sub></span>.</p>

      <div class="answer">
        <div class="label">What to show</div>
        <ul>
          <li>On <em>Taj Mahal</em> (and one more photo): blurred <span class="kbd">low = I*G</span>, high <span class="kbd">I−low</span> (visualized), and sharpened results for a couple of <span class="kbd">α</span>.</li>
          <li>Evaluation: take a sharp image → blur → re-sharpen. Compare with the original.</li>
        </ul>
      </div>

      <div class="gallery">
        <figure class="figure"><img src="p2/taj_original.jpg" alt="Taj original"/><figcaption class="figcap">Original (Taj)</figcaption></figure>
        <figure class="figure"><img src="p2/p21_taj_low.png" alt="Taj low"/><figcaption class="figcap">Low-pass (blur)</figcaption></figure>
        <figure class="figure"><img src="p2/p21_taj_high_vis.png" alt="Taj high"/><figcaption class="figcap">High-freq (scaled to view)</figcaption></figure>
        <figure class="figure"><img src="p2/p21_taj_unsharp_twopass.png" alt="Taj sharpened"/><figcaption class="figcap">Sharpened (two-pass)</figcaption></figure>
      </div>

      <div class="gallery">
        <figure class="figure"><img src="p2/lizard_original.jpg" alt="Lizard original"/><figcaption class="figcap">Original (Lizard)</figcaption></figure>
        <figure class="figure"><img src="p2/p21_lizard_low.png" alt="Lizard low"/><figcaption class="figcap">Lizard image: low-pass</figcaption></figure>
        <figure class="figure"><img src="p2/p21_lizard_high_vis.png" alt="Lizard high"/><figcaption class="figcap">Lizard image: high-freq</figcaption></figure>
        <figure class="figure"><img src="p2/p21_lizard_unsharp.png" alt="Lizard sharpened"/><figcaption class="figcap">Lizard image: sharpened</figcaption></figure>
      </div>

      <div class="gallery">
        <figure class="figure"><img src="p2/p21_taj_amt_0_5.png" alt="α=0.5"/><figcaption class="figcap">α = 0.5</figcaption></figure>
        <figure class="figure"><img src="p2/p21_taj_amt_1_0.png" alt="α=1.0"/><figcaption class="figcap">α = 1.0</figcaption></figure>
        <figure class="figure"><img src="p2/p21_taj_amt_1_5.png" alt="α=1.5"/><figcaption class="figcap">α = 1.5</figcaption></figure>
        <figure class="figure"><img src="p2/p21_taj_amt_2_0.png" alt="α=2.0"/><figcaption class="figcap">α = 2.0</figcaption></figure>
      </div>

      <div class="answer">
        <div class="label">Observation</div>
        <p>Small α cleans haze and restores crisp edges; very large α amplifies noise and halos near strong contrasts. Matching blur <span class="kbd">σ</span> to the image’s softness is key.</p>
      </div>
    </section>

    <!-- 2.2 -->
    <section class="section" id="part2-2">
      <h2>Part 2.2 — Hybrid Images</h2>
      <p>Blend the high-frequency component of one image with the low-frequency component of another. Up close you perceive the high-frequency subject; at a distance the low-frequency subject dominates.</p>

      <div class="callout">
        <strong>Pipeline</strong>: align → high-pass <span class="kbd">im_high − im_high*G(σ<sub>high</sub>)</span> → low-pass <span class="kbd">im_low*G(σ<sub>low</sub>)</span> → add → analyze FFTs.
      </div>

      <h3 style="margin-top:8px">Example A — Derek + Nutmeg</h3>
      <div class="gallery">
        <figure class="figure"><img src="p2/p22_pair3_im1.png" alt="im1"/><figcaption class="figcap">High-freq source (aligned)</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair3_im2.png" alt="im2"/><figcaption class="figcap">Low-freq source (aligned)</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair3_highpass_vis.png" alt="hp vis"/><figcaption class="figcap">High-pass (vis)</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair3_lowpass.png" alt="lp"/><figcaption class="figcap">Low-pass</figcaption></figure>
      </div>

      <div class="gallery">
        <figure class="figure"><img src="p2/p22_pair3_hybrid.png" alt="hybrid"/><figcaption class="figcap">Hybrid image</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair3_fft_im1.png" alt="fft im1"/><figcaption class="figcap">FFT (im1)</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair3_fft_highpass.png" alt="FFT high-pass"/><figcaption class="figcap">FFT (high-pass of im1)</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair3_fft_im2.png" alt="fft im2"/><figcaption class="figcap">FFT (im2)</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair3_fft_lowpass.png" alt="FFT low-pass"/><figcaption class="figcap">FFT (low-pass of im2)</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair3_fft_hybrid.png" alt="fft hyb"/><figcaption class="figcap">FFT (hybrid)</figcaption></figure>
      </div>

      <div class="answer">
          <div class="label">Cutoff (σ) used</div>
          <p>σ<sub>high</sub> = 4.0, σ<sub>low</sub> = 10.0 (tuned by visual inspection for crisp HF + stable LF).</p>
      </div>

      <h3>Example B — Pair 1</h3>
      <div class="gallery">
        <figure class="figure"><img src="p2/p22_pair1_im1.png" alt="pair1 im1"/><figcaption class="figcap">Input A</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair1_im2.png" alt="pair1 im2"/><figcaption class="figcap">Input B</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair1_hybrid.png" alt="pair1 hyb"/><figcaption class="figcap">Hybrid</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair1_fft_hybrid.png" alt="pair1 fft"/><figcaption class="figcap">FFT (hybrid)</figcaption></figure>
      </div>

      <h3>Example C — Pair 2</h3>
      <div class="gallery">
        <figure class="figure"><img src="p2/p22_pair2_im1.png" alt="pair2 im1"/><figcaption class="figcap">Input A</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair2_im2.png" alt="pair2 im2"/><figcaption class="figcap">Input B</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair2_hybrid.png" alt="pair2 hyb"/><figcaption class="figcap">Hybrid</figcaption></figure>
        <figure class="figure"><img src="p2/p22_pair2_fft_hybrid.png" alt="pair2 fft"/><figcaption class="figcap">FFT (hybrid)</figcaption></figure>
      </div>

      <div class="answer">
        <div class="label">Cutoff choices</div>
        <p>I tuned <span class="kbd">σ<sub>high</sub></span> to preserve crisp details without halos and <span class="kbd">σ<sub>low</sub></span> to keep global structure. Better alignment → stronger hybrid illusion.</p>
      </div>
    </section>

    <!-- 2.3 -->
    <section class="section" id="part2-3">
      <h2>Part 2.3 — Gaussian & Laplacian Stacks (No Downsampling)</h2>
      <p>Stacks keep full resolution at each level (unlike pyramids). Gaussian stack: repeated blur; Laplacian stack: differences of adjacent Gaussian levels, final residual low-pass kept in the last level.</p>

      <div class="gallery">
        <figure class="figure"><img src="p2/p23_orange_G0.png" alt="G0"/><figcaption class="figcap">G0</figcaption></figure>
        <figure class="figure"><img src="p2/p23_orange_G1.png" alt="G1"/><figcaption class="figcap">G1</figcaption></figure>
        <figure class="figure"><img src="p2/p23_orange_G2.png" alt="G2"/><figcaption class="figcap">G2</figcaption></figure>
        <figure class="figure"><img src="p2/p23_orange_G3.png" alt="G3"/><figcaption class="figcap">G3</figcaption></figure>
      </div>

      <div class="gallery">
        <figure class="figure"><img src="p2/p23_apple_G0.png" alt="G0"/><figcaption class="figcap">G0</figcaption></figure>
        <figure class="figure"><img src="p2/p23_apple_G1.png" alt="G1"/><figcaption class="figcap">G1</figcaption></figure>
        <figure class="figure"><img src="p2/p23_apple_G2.png" alt="G2"/><figcaption class="figcap">G2</figcaption></figure>
        <figure class="figure"><img src="p2/p23_apple_G3.png" alt="G3"/><figcaption class="figcap">G3</figcaption></figure>
      </div>

      <div class="gallery">
        <figure class="figure"><img src="p2/p23_orange_L0.png" alt="L0"/><figcaption class="figcap">L0 (band-pass)</figcaption></figure>
        <figure class="figure"><img src="p2/p23_orange_L1.png" alt="L1"/><figcaption class="figcap">L1</figcaption></figure>
        <figure class="figure"><img src="p2/p23_orange_L2.png" alt="L2"/><figcaption class="figcap">L2</figcaption></figure>
        <figure class="figure"><img src="p2/p23_orange_L3.png" alt="L3"/><figcaption class="figcap">L3 / residual</figcaption></figure>
      </div>

            <div class="gallery">
        <figure class="figure"><img src="p2/p23_apple_L0.png" alt="L0"/><figcaption class="figcap">L0 (band-pass)</figcaption></figure>
        <figure class="figure"><img src="p2/p23_apple_L1.png" alt="L1"/><figcaption class="figcap">L1</figcaption></figure>
        <figure class="figure"><img src="p2/p23_apple_L2.png" alt="L2"/><figcaption class="figcap">L2</figcaption></figure>
        <figure class="figure"><img src="p2/p23_apple_L3.png" alt="L3"/><figcaption class="figcap">L3 / residual</figcaption></figure>
      </div>

      <div class="answer">
        <div class="label">Note</div>
        <p>Visualize Laplacians with a symmetric mapping around 0 (I use <span class="kbd">0.5 + L/(2·max|L|)</span>) to see positive/negative detail.</p>
      </div>
    </section>

    <!-- 2.4 -->
    <section class="section" id="part2-4">
      <h2>Part 2.4 — Multiresolution Blending (the “Oraple”)</h2>
      <p>Blend two images by combining their Laplacian stacks with weights from the mask’s Gaussian stack. A binary step mask (vertical/horizontal seam) already works well; irregular masks enable creative composites.</p>

      <div class="callout">
        <strong>Algorithm</strong>: build stacks for A, B, and mask M∈[0,1]. For each level <span class="kbd">k</span>, blend <span class="kbd">Lᵏ = Mᵏ·Lᵏ_A + (1−Mᵏ)·Lᵏ_B</span>. Reconstruct with the blended stack.
      </div>

      <h3 style="margin-top:8px">Recreating Szeliski Fig. 3.42</h3>
      <div class="gallery">
        <figure class="figure"><img src="p2/p24_oraple_soft_mosaic.png" alt="oraple fig 3.42"/><figcaption class="figcap">3×4 mosaic (a…l)</figcaption></figure>
      </div>

      <h3>Straight-seam Oraple</h3>
      <div class="gallery">
        <figure class="figure"><img src="p2/p24_oraple_A.png" alt="apple"/><figcaption class="figcap">A (orange)</figcaption></figure>
        <figure class="figure"><img src="p2/p24_oraple_B.png" alt="orange"/><figcaption class="figcap">B (apple)</figcaption></figure>
        <figure class="figure"><img src="p2/p24_oraple_mask_soft.png" alt="mask"/><figcaption class="figcap">Step mask (Gaussian stack used)</figcaption></figure>
        <figure class="figure"><img src="p2/p24_oraple_blend.png" alt="blend"/><figcaption class="figcap">Blended result</figcaption></figure>
      </div>

      <h3>Straight-seam Lebrobe</h3>
      <div class="gallery">
        <figure class="figure"><img src="p2/p24_lebrobe_A.png" alt="apple"/><figcaption class="figcap">A (lebron)</figcaption></figure>
        <figure class="figure"><img src="p2/p24_lebrobe_B.png" alt="orange"/><figcaption class="figcap">B (kobe)</figcaption></figure>
        <figure class="figure"><img src="p2/p24_lebrobe_mask_soft.png" alt="mask"/><figcaption class="figcap">Step mask (Gaussian stack used)</figcaption></figure>
        <figure class="figure"><img src="p2/p24_lebrobe_blend.png" alt="blend"/><figcaption class="figcap">Blended result</figcaption></figure>
      </div>

      <h3>“Eye in Palm” (irregular ellipse mask)</h3>
      <div class="gallery">
        <figure class="figure"><img src="p2/hand.png" alt="hand"/><figcaption class="figcap">Hand (base)</figcaption></figure>
        <figure class="figure"><img src="p2/eye.png" alt="eye"/><figcaption class="figcap">Eye (placed)</figcaption></figure>
        <figure class="figure"><img src="p2/p24_eye_in_palm_mask.png" alt="mask"/><figcaption class="figcap">Mask (ellipse)</figcaption></figure>
        <figure class="figure"><img src="p2/p24_eye_in_palm_blend.png" alt="final"/><figcaption class="figcap">Final multi-res blend</figcaption></figure>
      </div>
    </section>


    
  </main>

  <footer class="container footer">
    <div>Project 2 · CS180/280A</div>
  </footer>
</body>
</html>
